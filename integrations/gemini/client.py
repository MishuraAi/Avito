"""
ü§ñ –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è Google Gemini API

–≠—Ç–æ—Ç –º–æ–¥—É–ª—å —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Gemini:
- –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞ —Å API
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø–æ–≤—Ç–æ—Ä—ã –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
- –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –¥–∏–∞–ª–æ–≥–∞
- –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ç–æ–∫–µ–Ω–æ–≤ –∏ —Å—Ç–æ–∏–º–æ—Å—Ç–∏
- –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤
- –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∏–ª—å—Ç—Ä–æ–≤ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏

–ú–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏–µ: src/integrations/gemini/client.py
"""

import asyncio
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
import hashlib

import google.generativeai as genai
import aiohttp
from aiohttp import ClientSession, ClientTimeout

from ..base import BaseIntegration
from . import (
    GeminiIntegrationConfig,
    GeminiMessage,
    GeminiResponse,
    GeminiModel,
    GeminiRole,
    GeminiAPIException,
    GeminiRateLimitException,
    GeminiSafetyException
)


# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞
logger = logging.getLogger(__name__)


class GeminiAPIClient(BaseIntegration):
    """
    ü§ñ –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç –¥–ª—è Google Gemini API
    
    –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤—ã–µ –º–µ—Ç–æ–¥—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Gemini:
    - –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
    - –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞–º–∏
    - –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
    - –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    """
    
    def __init__(self, config: GeminiIntegrationConfig):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Gemini –∫–ª–∏–µ–Ω—Ç–∞
        
        Args:
            config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å Gemini
        """
        
        super().__init__("gemini_api", config.__dict__)
        
        self.config = config
        self.model = None
        
        # –î–∏–∞–ª–æ–≥–æ–≤—ã–µ —Å–µ—Å—Å–∏–∏
        self.active_sessions: Dict[str, List[GeminiMessage]] = {}
        
        # –ö–µ—à –æ—Ç–≤–µ—Ç–æ–≤
        self.response_cache: Dict[str, Tuple[GeminiResponse, datetime]] = {}
        self.cache_ttl = timedelta(hours=1)
        
        # –¢–æ–∫–µ–Ω —Ç—Ä–µ–∫–∏–Ω–≥
        self.token_usage = {
            "total_prompt_tokens": 0,
            "total_completion_tokens": 0,
            "total_requests": 0,
            "estimated_cost": 0.0
        }
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–≤—Ç–æ—Ä–æ–≤
        self.retry_delays = [1, 2, 4, 8, 16]  # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
        
        logger.info("Gemini API –∫–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å –º–æ–¥–µ–ª—å—é %s", config.model.value)
    
    async def connect(self) -> bool:
        """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Gemini API"""
        
        try:
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ API –∫–ª—é—á–∞
            genai.configure(api_key=self.config.api_key)
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
            self.model = genai.GenerativeModel(self.config.model.value)
            
            # –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
            test_response = await self._make_generation_request(
                "–û—Ç–≤–µ—Ç—å –æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º: OK",
                max_retries=1
            )
            
            if test_response and "ok" in test_response.text.lower():
                self.is_connected = True
                self.connection_time = datetime.now()
                logger.info("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Gemini API —É—Å–ø–µ—à–Ω–æ")
                return True
            else:
                logger.error("‚ùå –¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Gemini API –Ω–µ –ø—Ä–æ—à–µ–ª")
                return False
                
        except Exception as e:
            self.last_error = str(e)
            logger.error("‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Gemini API: %s", e)
            return False
    
    async def disconnect(self) -> None:
        """–û—Ç–∫–ª—é—á–µ–Ω–∏–µ –æ—Ç Gemini API"""
        
        self.model = None
        self.is_connected = False
        
        # –û—á–∏—â–∞–µ–º –∫–µ—à–∏
        self.active_sessions.clear()
        self.response_cache.clear()
        
        logger.info("–û—Ç–∫–ª—é—á–µ–Ω–∏–µ –æ—Ç Gemini API")
    
    async def health_check(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è API"""
        
        try:
            if not self.model:
                return False
            
            # –ü—Ä–æ—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            response = await self._make_generation_request(
                "–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç—ã API. –û—Ç–≤–µ—Ç—å: —Ä–∞–±–æ—Ç–∞–µ—Ç",
                max_retries=1
            )
            
            return response is not None and "—Ä–∞–±–æ—Ç–∞–µ—Ç" in response.text.lower()
            
        except Exception as e:
            logger.error("–û—à–∏–±–∫–∞ health check Gemini API: %s", e)
            return False
    
    async def generate_text(
        self,
        prompt: str,
        session_id: Optional[str] = None,
        system_instruction: Optional[str] = None,
        use_cache: bool = True
    ) -> Optional[GeminiResponse]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        
        Args:
            prompt: –¢–µ–∫—Å—Ç –ø—Ä–æ–º–ø—Ç–∞
            session_id: ID —Å–µ—Å—Å–∏–∏ –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            system_instruction: –°–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            use_cache: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ
            
        Returns:
            Optional[GeminiResponse]: –û—Ç–≤–µ—Ç –æ—Ç Gemini –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        
        start_time = datetime.now()
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à
            if use_cache:
                cache_key = self._generate_cache_key(prompt, session_id, system_instruction)
                cached_response = self._get_cached_response(cache_key)
                
                if cached_response:
                    logger.debug("–û—Ç–≤–µ—Ç –≤–∑—è—Ç –∏–∑ –∫–µ—à–∞")
                    return cached_response
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞
            messages = self._prepare_conversation_context(prompt, session_id, system_instruction)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
            response = await self._make_generation_request(messages)
            
            if response:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫–µ—à
                if use_cache:
                    self._cache_response(cache_key, response)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å–µ—Å—Å–∏—é
                if session_id:
                    self._update_session(session_id, prompt, response.text)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
                processing_time = (datetime.now() - start_time).total_seconds()
                self.update_metrics(True, processing_time)
                self._update_token_usage(response)
                
                logger.info("–¢–µ–∫—Å—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: %d —Å–∏–º–≤–æ–ª–æ–≤ –∑–∞ %.2f —Å–µ–∫", 
                           len(response.text), processing_time)
            
            return response
            
        except Exception as e:
            processing_time = (datetime.now() - start_time).total_seconds()
            self.update_metrics(False, processing_time)
            logger.error("–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞: %s", e)
            return None
    
    async def generate_with_conversation(
        self,
        prompt: str,
        conversation_history: List[GeminiMessage],
        system_instruction: Optional[str] = None
    ) -> Optional[GeminiResponse]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å —è–≤–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–µ–π –¥–∏–∞–ª–æ–≥–∞
        
        Args:
            prompt: –ù–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç
            conversation_history: –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞
            system_instruction: –°–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è
            
        Returns:
            Optional[GeminiResponse]: –û—Ç–≤–µ—Ç –æ—Ç Gemini
        """
        
        try:
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
            full_messages = conversation_history.copy()
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—É—é –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –µ—Å–ª–∏ –µ—Å—Ç—å
            if system_instruction:
                system_msg = GeminiMessage(
                    role=GeminiRole.SYSTEM,
                    content=system_instruction
                )
                full_messages.insert(0, system_msg)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç
            user_msg = GeminiMessage(
                role=GeminiRole.USER,
                content=prompt
            )
            full_messages.append(user_msg)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
            response = await self._make_generation_request(full_messages)
            
            return response
            
        except Exception as e:
            logger.error("–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å –∏—Å—Ç–æ—Ä–∏–µ–π: %s", e)
            return None
    
    async def analyze_content(
        self,
        content: str,
        analysis_type: str = "sentiment"
    ) -> Optional[Dict[str, Any]]:
        """
        –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å –ø–æ–º–æ—â—å—é Gemini
        
        Args:
            content: –ö–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            analysis_type: –¢–∏–ø –∞–Ω–∞–ª–∏–∑–∞ (sentiment, classification, etc.)
            
        Returns:
            Optional[Dict]: –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
        """
        
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            analysis_prompts = {
                "sentiment": f"""
                –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é –æ–∫—Ä–∞—Å–∫—É —ç—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –∏ –≤–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ JSON:
                {{"sentiment": "positive/negative/neutral", "confidence": 0.0-1.0, "explanation": "–æ–±—ä—è—Å–Ω–µ–Ω–∏–µ"}}
                
                –¢–µ–∫—Å—Ç: {content}
                """,
                
                "classification": f"""
                –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–π —ç—Ç–æ—Ç —Ç–µ–∫—Å—Ç –ø–æ —Ç–∏–ø—É —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –ê–≤–∏—Ç–æ –∏ –≤–µ—Ä–Ω–∏ JSON:
                {{"type": "price_question/availability/meeting_request/general", "confidence": 0.0-1.0}}
                
                –¢–µ–∫—Å—Ç: {content}
                """,
                
                "urgency": f"""
                –û–ø—Ä–µ–¥–µ–ª–∏ —Å—Ä–æ—á–Ω–æ—Å—Ç—å —ç—Ç–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ –≤–µ—Ä–Ω–∏ JSON:
                {{"urgency": "low/medium/high", "confidence": 0.0-1.0, "reasoning": "–æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ"}}
                
                –¢–µ–∫—Å—Ç: {content}
                """
            }
            
            prompt = analysis_prompts.get(analysis_type, analysis_prompts["sentiment"])
            
            response = await self.generate_text(prompt, use_cache=True)
            
            if response:
                # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –æ—Ç–≤–µ—Ç
                try:
                    return json.loads(response.text.strip())
                except json.JSONDecodeError:
                    # –ï—Å–ª–∏ –Ω–µ JSON, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ —Ç–µ–∫—Å—Ç
                    return {"result": response.text, "type": "text"}
            
            return None
            
        except Exception as e:
            logger.error("–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞: %s", e)
            return None
    
    def create_session(self, session_id: str, system_instruction: Optional[str] = None) -> None:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –¥–∏–∞–ª–æ–≥–æ–≤–æ–π —Å–µ—Å—Å–∏–∏
        
        Args:
            session_id: –£–Ω–∏–∫–∞–ª—å–Ω—ã–π ID —Å–µ—Å—Å–∏–∏
            system_instruction: –°–∏—Å—Ç–µ–º–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–ª—è —Å–µ—Å—Å–∏–∏
        """
        
        self.active_sessions[session_id] = []
        
        if system_instruction:
            system_msg = GeminiMessage(
                role=GeminiRole.SYSTEM,
                content=system_instruction
            )
            self.active_sessions[session_id].append(system_msg)
        
        logger.debug("–°–æ–∑–¥–∞–Ω–∞ —Å–µ—Å—Å–∏—è %s", session_id)
    
    def clear_session(self, session_id: str) -> None:
        """
        –û—á–∏—Å—Ç–∫–∞ –¥–∏–∞–ª–æ–≥–æ–≤–æ–π —Å–µ—Å—Å–∏–∏
        
        Args:
            session_id: ID —Å–µ—Å—Å–∏–∏ –¥–ª—è –æ—á–∏—Å—Ç–∫–∏
        """
        
        if session_id in self.active_sessions:
            del self.active_sessions[session_id]
            logger.debug("–°–µ—Å—Å–∏—è %s –æ—á–∏—â–µ–Ω–∞", session_id)
    
    def get_session_history(self, session_id: str) -> List[GeminiMessage]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ —Å–µ—Å—Å–∏–∏
        
        Args:
            session_id: ID —Å–µ—Å—Å–∏–∏
            
        Returns:
            List[GeminiMessage]: –ò—Å—Ç–æ—Ä–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π
        """
        
        return self.active_sessions.get(session_id, []).copy()
    
    async def _make_generation_request(
        self,
        content,
        max_retries: Optional[int] = None
    ) -> Optional[GeminiResponse]:
        """
        –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –∫ Gemini API —Å –ø–æ–≤—Ç–æ—Ä–∞–º–∏
        
        Args:
            content: –ö–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (—Å—Ç—Ä–æ–∫–∞ –∏–ª–∏ —Å–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π)
            max_retries: –ú–∞–∫—Å–∏–º—É–º –ø–æ–≤—Ç–æ—Ä–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞)
            
        Returns:
            Optional[GeminiResponse]: –û—Ç–≤–µ—Ç –æ—Ç API
        """
        
        if max_retries is None:
            max_retries = self.config.max_retries
        
        last_exception = None
        
        for attempt in range(max_retries + 1):
            try:
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
                generation_config = self.config.get_generation_config()
                
                # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å
                if isinstance(content, str):
                    # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
                    response = await self.model.generate_content_async(
                        content,
                        generation_config=generation_config
                    )
                else:
                    # –î–∏–∞–ª–æ–≥ –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
                    formatted_messages = [msg.to_dict() for msg in content]
                    response = await self.model.generate_content_async(
                        formatted_messages,
                        generation_config=generation_config
                    )
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Ñ–∏–ª—å—Ç—Ä—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
                if hasattr(response, 'prompt_feedback'):
                    if response.prompt_feedback and response.prompt_feedback.block_reason:
                        raise GeminiSafetyException(
                            f"–ö–æ–Ω—Ç–µ–Ω—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω —Ñ–∏–ª—å—Ç—Ä–∞–º–∏: {response.prompt_feedback.block_reason}",
                            []
                        )
                
                # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
                return self._parse_response(response)
                
            except Exception as e:
                last_exception = e
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω—É–∂–Ω–æ –ª–∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å
                if attempt < max_retries:
                    if self._should_retry(e):
                        delay = self.retry_delays[min(attempt, len(self.retry_delays) - 1)]
                        logger.warning("–ü–æ–ø—ã—Ç–∫–∞ %d/%d –Ω–µ—É–¥–∞—á–Ω–∞, –ø–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ %d —Å–µ–∫: %s", 
                                     attempt + 1, max_retries + 1, delay, e)
                        await asyncio.sleep(delay)
                        continue
                
                # –ë–æ–ª—å—à–µ –Ω–µ –ø–æ–≤—Ç–æ—Ä—è–µ–º
                break
        
        # –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã
        logger.error("–í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã, –ø–æ—Å–ª–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞: %s", last_exception)
        return None
    
    def _should_retry(self, exception: Exception) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å—Ç–æ–∏—Ç –ª–∏ –ø–æ–≤—Ç–æ—Ä—è—Ç—å –∑–∞–ø—Ä–æ—Å"""
        
        # –ü–æ–≤—Ç–æ—Ä—è–µ–º –ø—Ä–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ—à–∏–±–∫–∞—Ö
        retry_conditions = [
            "timeout" in str(exception).lower(),
            "connection" in str(exception).lower(),
            "500" in str(exception),
            "502" in str(exception),
            "503" in str(exception),
            "429" in str(exception)  # Rate limit
        ]
        
        return any(retry_conditions)
    
    def _parse_response(self, response) -> GeminiResponse:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –æ—Ç Gemini API"""
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
        text = response.text if hasattr(response, 'text') else str(response)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
        prompt_tokens = None
        completion_tokens = None
        total_tokens = None
        
        if hasattr(response, 'usage_metadata'):
            usage = response.usage_metadata
            prompt_tokens = getattr(usage, 'prompt_token_count', None)
            completion_tokens = getattr(usage, 'candidates_token_count', None)
            total_tokens = getattr(usage, 'total_token_count', None)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∏—á–∏–Ω—É –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        finish_reason = None
        if hasattr(response, 'candidates') and response.candidates:
            candidate = response.candidates[0]
            finish_reason = getattr(candidate, 'finish_reason', None)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–µ–π—Ç–∏–Ω–≥–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
        safety_ratings = None
        if hasattr(response, 'candidates') and response.candidates:
            candidate = response.candidates[0]
            if hasattr(candidate, 'safety_ratings'):
                safety_ratings = [
                    {
                        "category": rating.category.name,
                        "probability": rating.probability.name
                    }
                    for rating in candidate.safety_ratings
                ]
        
        return GeminiResponse(
            text=text,
            model_used=self.config.model.value,
            prompt_tokens=prompt_tokens,
            completion_tokens=completion_tokens,
            total_tokens=total_tokens,
            finish_reason=finish_reason.name if finish_reason else None,
            safety_ratings=safety_ratings,
            raw_response=response._pb if hasattr(response, '_pb') else None
        )
    
    def _prepare_conversation_context(
        self,
        prompt: str,
        session_id: Optional[str],
        system_instruction: Optional[str]
    ) -> List[GeminiMessage]:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–∏–∞–ª–æ–≥–∞"""
        
        messages = []
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—É—é –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é
        if system_instruction:
            messages.append(GeminiMessage(
                role=GeminiRole.SYSTEM,
                content=system_instruction
            ))
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å–µ—Å—Å–∏–∏
        if session_id and session_id in self.active_sessions:
            messages.extend(self.active_sessions[session_id])
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç
        messages.append(GeminiMessage(
            role=GeminiRole.USER,
            content=prompt
        ))
        
        return messages
    
    def _update_session(self, session_id: str, user_prompt: str, ai_response: str) -> None:
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ —Å–µ—Å—Å–∏–∏"""
        
        if session_id not in self.active_sessions:
            self.active_sessions[session_id] = []
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –∏—Å—Ç–æ—Ä–∏—é
        user_msg = GeminiMessage(role=GeminiRole.USER, content=user_prompt)
        ai_msg = GeminiMessage(role=GeminiRole.MODEL, content=ai_response)
        
        self.active_sessions[session_id].extend([user_msg, ai_msg])
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –∏—Å—Ç–æ—Ä–∏–∏ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 20 —Å–æ–æ–±—â–µ–Ω–∏–π)
        if len(self.active_sessions[session_id]) > 20:
            self.active_sessions[session_id] = self.active_sessions[session_id][-20:]
    
    def _generate_cache_key(
        self,
        prompt: str,
        session_id: Optional[str],
        system_instruction: Optional[str]
    ) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–ª—é—á–∞ –∫–µ—à–∞"""
        
        key_parts = [
            prompt,
            session_id or "",
            system_instruction or "",
            self.config.model.value,
            str(self.config.temperature)
        ]
        
        combined = "|".join(key_parts)
        return hashlib.md5(combined.encode()).hexdigest()
    
    def _get_cached_response(self, cache_key: str) -> Optional[GeminiResponse]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –∏–∑ –∫–µ—à–∞"""
        
        if cache_key in self.response_cache:
            response, timestamp = self.response_cache[cache_key]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º TTL
            if datetime.now() - timestamp < self.cache_ttl:
                return response
            else:
                # –£–¥–∞–ª—è–µ–º —É—Å—Ç–∞—Ä–µ–≤—à–∏–π –∫–µ—à
                del self.response_cache[cache_key]
        
        return None
    
    def _cache_response(self, cache_key: str, response: GeminiResponse) -> None:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –≤ –∫–µ—à"""
        
        self.response_cache[cache_key] = (response, datetime.now())
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∫–µ—à–∞
        if len(self.response_cache) > 500:
            # –£–¥–∞–ª—è–µ–º 20% —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π
            old_keys = sorted(
                self.response_cache.keys(),
                key=lambda k: self.response_cache[k][1]
            )[:100]
            
            for key in old_keys:
                del self.response_cache[key]
    
    def _update_token_usage(self, response: GeminiResponse) -> None:
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤"""
        
        if response.prompt_tokens:
            self.token_usage["total_prompt_tokens"] += response.prompt_tokens
        
        if response.completion_tokens:
            self.token_usage["total_completion_tokens"] += response.completion_tokens
        
        self.token_usage["total_requests"] += 1
        
        # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ (—É—Å–ª–æ–≤–Ω—ã–µ –µ–¥–∏–Ω–∏—Ü—ã)
        if response.total_tokens:
            self.token_usage["estimated_cost"] += response.total_tokens * 0.0001
    
    def get_extended_metrics(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫"""
        
        base_metrics = self.get_metrics()
        
        return {
            **base_metrics,
            "token_usage": self.token_usage,
            "active_sessions": len(self.active_sessions),
            "cache_size": len(self.response_cache),
            "model_used": self.config.model.value
        }
    
    def clear_cache(self) -> None:
        """–û—á–∏—Å—Ç–∫–∞ –≤—Å–µ—Ö –∫–µ—à–µ–π"""
        
        self.response_cache.clear()
        logger.info("–ö–µ—à Gemini –∫–ª–∏–µ–Ω—Ç–∞ –æ—á–∏—â–µ–Ω")


# –§–∞–±—Ä–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
async def create_gemini_client(config: GeminiIntegrationConfig) -> GeminiAPIClient:
    """
    üè≠ –°–æ–∑–¥–∞–Ω–∏–µ –∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ Gemini –∫–ª–∏–µ–Ω—Ç–∞
    
    Args:
        config: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
        
    Returns:
        GeminiAPIClient: –ì–æ—Ç–æ–≤—ã–π –∫ —Ä–∞–±–æ—Ç–µ –∫–ª–∏–µ–Ω—Ç
    """
    
    if not config.validate():
        raise ValueError("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Gemini API")
    
    client = GeminiAPIClient(config)
    
    # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ API
    success = await client.connect()
    if not success:
        raise GeminiAPIException("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Gemini API", 0)
    
    logger.info("Gemini API –∫–ª–∏–µ–Ω—Ç —Å–æ–∑–¥–∞–Ω –∏ –ø–æ–¥–∫–ª—é—á–µ–Ω")
    return client